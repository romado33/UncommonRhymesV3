from __future__ import annotations
import os, sqlite3
from typing import Any, Dict, List, Tuple, Optional

from .data.paths import words_db
from .phonetics import parse_pron, k_keys, coda, meter_name, tail_distance

# ----------------- DB helpers -----------------
def _con(path: str) -> sqlite3.Connection:
    con = sqlite3.connect(path)
    con.row_factory = sqlite3.Row
    return con

def _query_words(where_sql: str, params: Tuple[Any, ...], order: Optional[str]=None, limit: Optional[int]=None) -> List[Dict[str, Any]]:
    sql = "SELECT word, pron, syls, stress, zipf, k1, k2 FROM words WHERE " + where_sql
    if order: sql += f" ORDER BY {order}"
    if limit: sql += f" LIMIT {int(limit)}"
    with _con(words_db()) as con:
        return [dict(r) for r in con.execute(sql, params).fetchall()]

def _zipf_band(rows: List[Dict[str, Any]], zmin: float, zmax: float) -> List[Dict[str, Any]]:
    out = []
    for r in rows:
        z = r.get("zipf")
        if z is None: 
            continue
        try:
            zf = float(z)
        except Exception:
            continue
        if zmin <= zf <= zmax:
            out.append(r)
    return out

def _enrich(r: Dict[str, Any], why: str) -> Dict[str, Any]:
    stress = r.get("stress") or ""
    return {
        "word": r.get("word",""),
        "syls": int(r.get("syls") or 0),
        "stress": stress,
        "meter": meter_name(stress),
        "zipf": r.get("zipf"),
        "why": why,
    }

# simple stoplist for modifiers
STOP = {"a","an","the","of","to","and","in","on","for","by","at","with","from"}

# ----------------- strictness helpers (config via env) -----------------
SLANT_CODA_MAX = int(os.getenv("UR_SLANT_CODA_MAX","1"))
MULTI_CODA_MAX = int(os.getenv("UR_MULTI_CODA_MAX","0"))  # 0 = exact coda for head

# ----------------- selectors -----------------
def _select_perfect(k2: str, zmin: float, zmax: float, limit: int) -> List[Dict[str,Any]]:
    rows = _query_words("k2 = ?", (k2,), order="zipf DESC", limit=None)
    rows = _zipf_band(rows, zmin, zmax)
    return rows[:limit]

def _select_slant(k1: str, zmin: float, zmax: float, q_tail_phones: List[str], exclude_words: set, limit: int) -> List[Dict[str,Any]]:
    pool = _zipf_band(_query_words("k1 = ?", (k1,), order="zipf DESC", limit=None), zmin, zmax)
    pool = [r for r in pool if r.get("word") not in exclude_words]
    scored: List[Tuple[float,int,Dict[str,Any]]] = []
    for r in pool:
        d = tail_distance(q_tail_phones, parse_pron(r.get("pron","")))
        if d <= SLANT_CODA_MAX:
            z = float(r.get("zipf") or 0.0)
            scored.append((-z, d, r))
    scored.sort(key=lambda t: (t[0], t[1]))  # most common first, then tighter coda
    return [r for _,__,r in scored[:limit]]

def _multiword_from_cmu_strict(k2: str, k1: str, zmax_multi: float, zmin: float, max_items: int, min_each: int) -> Tuple[List[Dict[str, Any]], int]:
    # heads: strict k2 first, then near-perfect if starving (only if MULTI_CODA_MAX > 0)
    heads = _zipf_band(_query_words("k2 = ?", (k2,), order="zipf DESC", limit=None), zmin, zmax_multi)
    if len(heads) < min_each:
        k1_rows = _zipf_band(_query_words("k1 = ?", (k1,), order="zipf DESC", limit=None), zmin, zmax_multi)
        if MULTI_CODA_MAX > 0 and (heads or k1_rows):
            # approximate query coda from first available head, else from k1_rows
            base = heads[0] if heads else k1_rows[0]
            q_tail = coda(parse_pron(base.get("pron","")))
            for r in k1_rows:
                d = tail_distance(q_tail, parse_pron(r.get("pron","")))
                if d <= MULTI_CODA_MAX:
                    heads.append(r)

    # modifiers: frequent, short
    mods = _query_words("zipf >= ? AND syls <= ?", (4.2, 2), order="zipf DESC", limit=800)
    mods = [m for m in mods if (m.get("word") or "").lower() not in STOP]

    phrases: List[Dict[str, Any]] = []
    seen = set()
    for h in heads:
        hw = (h.get("word") or "").strip()
        if not hw: 
            continue
        h_syls = int(h.get("syls") or 0)
        h_str  = h.get("stress","") or ""
        for m in mods:
            mw = (m.get("word") or "").strip()
            if not mw:
                continue
            ph = f"{mw} {hw}"
            if ph in seen:
                continue
            syls = int(m.get("syls") or 0) + h_syls
            stress = f"{m.get('stress','')}{h_str}"
            phrases.append({
                "word": ph,
                "syls": syls,
                "stress": stress,
                "meter": meter_name(stress),
                "why": "multiword (modifier + head: strict/near-perfect tail)",
            })
            seen.add(ph)
            if len(phrases) >= max_items:
                break
        if len(phrases) >= max_items:
            break

    return phrases[:max_items], len(phrases)

# ----------------- main entry -----------------
def search_all_categories(
    term: str,
    max_items: int = 20,
    relax_rap: bool = True,
    include_rap: bool = False,
    zipf_max: float = 4.0,
    min_each: int = 10,
    zipf_max_multi: float = 5.5,
):
    q = (term or "").strip().lower()
    if not q:
# --- recovery path: widen filters if all buckets empty before final return ---
_un = uncommon if "uncommon" in locals() else []
_sl = slant if "slant" in locals() else []
_mw = multiword if "multiword" in locals() else []
_rt = rap_targets if "rap_targets" in locals() else []

if not (_un or _sl or _mw or _rt):
    try:
        res2 = search_all_categories(term,
                                     max_items=max_items,
                                     relax_rap=True,
                                     include_rap=False,
                                     zipf_max=5.5,
                                     min_each=max(6, min_each // 2),
                                     zipf_max_multi=7.0)
        if isinstance(res2, dict) and any(res2.get(k) for k in ["uncommon","slant","multiword","rap_targets"]):
            return res2
    except Exception:
        pass

    try:
        rhy = [w["word"] for w in dm.related(term, "rhy", max_items=max_items)] if hasattr(dm, "related") else []
        nry = [w["word"] for w in getattr(dm, "near_rhymes", lambda t, max_items=20: [])(term, max_items=max_items)]
        if rhy or nry:
            return {"uncommon": rhy[:max_items],
                    "slant": nry[:max_items],
                    "multiword": [],
                    "rap_targets": []}
    except Exception:
        pass
        return {"uncommon": [], "slant": [], "multiword": [], "rap_targets": []}

    # assume a CMU dict loader and a zipf map exist on module singletons:
    cmu = globals().get("CMU_DICT", {})
    meta_zipf = globals().get("ZIPF_MAP", {})

    # best-effort: if a TTS fallback parser exists, reuse the module’s helper:
    qp = parse_pron(q) if "parse_pron" in globals() else cmu.get(q, [])

    if not qp:
# --- recovery path: widen filters if all buckets empty before final return ---
_un = uncommon if "uncommon" in locals() else []
_sl = slant if "slant" in locals() else []
_mw = multiword if "multiword" in locals() else []
_rt = rap_targets if "rap_targets" in locals() else []

if not (_un or _sl or _mw or _rt):
    try:
        res2 = search_all_categories(term,
                                     max_items=max_items,
                                     relax_rap=True,
                                     include_rap=False,
                                     zipf_max=5.5,
                                     min_each=max(6, min_each // 2),
                                     zipf_max_multi=7.0)
        if isinstance(res2, dict) and any(res2.get(k) for k in ["uncommon","slant","multiword","rap_targets"]):
            return res2
    except Exception:
        pass

    try:
        rhy = [w["word"] for w in dm.related(term, "rhy", max_items=max_items)] if hasattr(dm, "related") else []
        nry = [w["word"] for w in getattr(dm, "near_rhymes", lambda t, max_items=20: [])(term, max_items=max_items)]
        if rhy or nry:
            return {"uncommon": rhy[:max_items],
                    "slant": nry[:max_items],
                    "multiword": [],
                    "rap_targets": []}
    except Exception:
        pass
        return {"uncommon": [], "slant": [], "multiword": [], "rap_targets": []}

    return build_buckets_cmu_only(
        q, cmu, meta_zipf,
        max_items=max_items,
        relax_rap=relax_rap,
        include_rap=False,
        zipf_max=zipf_max,
        min_each=min_each,
        zipf_max_multi=zipf_max_multi
    )

    q_phones = parse_pron(q) or []
    if not q_phones:
# --- recovery path: widen filters if all buckets empty before final return ---
_un = uncommon if "uncommon" in locals() else []
_sl = slant if "slant" in locals() else []
_mw = multiword if "multiword" in locals() else []
_rt = rap_targets if "rap_targets" in locals() else []

if not (_un or _sl or _mw or _rt):
    try:
        res2 = search_all_categories(term,
                                     max_items=max_items,
                                     relax_rap=True,
                                     include_rap=False,
                                     zipf_max=5.5,
                                     min_each=max(6, min_each // 2),
                                     zipf_max_multi=7.0)
        if isinstance(res2, dict) and any(res2.get(k) for k in ["uncommon","slant","multiword","rap_targets"]):
            return res2
    except Exception:
        pass

    try:
        rhy = [w["word"] for w in dm.related(term, "rhy", max_items=max_items)] if hasattr(dm, "related") else []
        nry = [w["word"] for w in getattr(dm, "near_rhymes", lambda t, max_items=20: [])(term, max_items=max_items)]
        if rhy or nry:
            return {"uncommon": rhy[:max_items],
                    "slant": nry[:max_items],
                    "multiword": [],
                    "rap_targets": []}
    except Exception:
        pass
        return {"uncommon": [], "slant": [], "multiword": [], "rap_targets": []}

    # robustly extract last two keys as (k1, k2)
    keys = k_keys(q_phones)
    if isinstance(keys, (tuple, list)):
        k2 = keys[-1] if len(keys) >= 1 else ""
        k1 = keys[-2] if len(keys) >= 2 else k2
    else:
        k1 = k2 = keys

    q_tail = coda(q_phones)

    zipf_min = float(os.getenv("UR_UNCOMMON_ZIPF_MIN", "2.5"))
    zmax     = float(zipf_max)
    zmax_m   = float(zipf_max_multi)
    min_req  = int(min_each)

    # PERFECT (strict tail match, k2 only) — sort most common → least common
    strict_pool = _select_perfect(k2, zipf_min, zmax, limit=10000)
    strict_pool.sort(key=lambda r: (-(r.get("zipf") if r.get("zipf") is not None else 0)))
    uncommon = [_enrich(r, f"strict rhyme (k2={k2})") for r in strict_pool[:max_items]]

    # SLANT (same vowel nucleus + small coda edit), exclude strict
    perfect_words = {r["word"] for r in strict_pool if r.get("word")}
    slant_ranked = _select_slant(k1, zipf_min, zmax, q_tail, perfect_words, limit=max_items*3)
    slant = [_enrich(r, f"assonance + coda≤{SLANT_CODA_MAX}") for r in slant_ranked[:max_items]]

    # MULTIWORD (modifier + head strict/near-perfect)
    multi, _total = _multiword_from_cmu_strict(k2, k1, zmax_m, zipf_min, max_items=max_items, min_each=min_req)

    # RAP (placeholder until DB is wired)
    rap_targets: List[Dict[str, Any]] = []
    if include_rap:
        rap_targets = []
# --- recovery path: widen filters if all buckets empty before final return ---
_un = uncommon if "uncommon" in locals() else []
_sl = slant if "slant" in locals() else []
_mw = multiword if "multiword" in locals() else []
_rt = rap_targets if "rap_targets" in locals() else []

if not (_un or _sl or _mw or _rt):
    try:
        res2 = search_all_categories(term,
                                     max_items=max_items,
                                     relax_rap=True,
                                     include_rap=False,
                                     zipf_max=5.5,
                                     min_each=max(6, min_each // 2),
                                     zipf_max_multi=7.0)
        if isinstance(res2, dict) and any(res2.get(k) for k in ["uncommon","slant","multiword","rap_targets"]):
            return res2
    except Exception:
        pass

    try:
        rhy = [w["word"] for w in dm.related(term, "rhy", max_items=max_items)] if hasattr(dm, "related") else []
        nry = [w["word"] for w in getattr(dm, "near_rhymes", lambda t, max_items=20: [])(term, max_items=max_items)]
        if rhy or nry:
            return {"uncommon": rhy[:max_items],
                    "slant": nry[:max_items],
                    "multiword": [],
                    "rap_targets": []}
    except Exception:
        pass

    return {
        "uncommon": uncommon[:max_items],
        "slant": slant[:max_items],
        "multiword": multi[:max_items],
        "rap_targets": rap_targets[:max_items],
    }

# === BEGIN CMU CORE RHYMER ===
import re

_VOWELS = {"AA","AE","AH","AO","AW","AY","EH","ER","EY","IH","IY","OW","OY","UH","UW"}

def _stress_digit(p):  # 'AH1' -> 1, 'L' -> -1
    m = re.search(r'(\d)', p)
    return int(m.group(1)) if m else -1

def _strip_stress(p):  # 'AH1' -> 'AH'
    return re.sub(r'\d','',p)

def _split_syllables(phones):
    # naive syllable split: every vowel (with/without stress) starts a syllable
    syl = []
    cur = []
    for ph in phones:
        cur.append(ph)
        if _strip_stress(ph) in _VOWELS:
            syl.append(cur)
            cur = []
    if cur: syl[-1].extend(cur) if syl else syl.append(cur)
    return syl

def _last_syllable_key(phones):
    syls = _split_syllables(phones)
    if not syls: return None, None
    last = syls[-1]
    # perfect key = vowel(with stress) + following consonants (rime); keep stress
    # slant key   = vowel class(without stress) only
    # find the last vowel index in last syllable
    vi = None
    for i in range(len(last)-1, -1, -1):
        if _strip_stress(last[i]) in _VOWELS:
            vi = i; break
    if vi is None: return None, None
    perfect = tuple(last[vi:])                   # keep stress + coda
    slant   = (_strip_stress(last[vi]),)         # vowel class only
    return perfect, slant

def _cmu_pron(word, cmu):
    w = word.lower()
    return cmu.get(w) or []

def _zipf_ok(z, ceiling):
    try:
        return (z is None) or (float(z) <= float(ceiling))
    except:
        return True

def _rarity(v):  # lower rarity first inside the uncommon window
    # if you’re storing Zipf, treat None as +inf so it sorts to the end
    try:
        return float(v) if v is not None else 9e9
    except:
        return 9e9

def _collect_cmu_candidates(query_phones, cmu, meta_zipf, zipf_max, max_items, slant=False):
    qk_perfect, qk_slant = _last_syllable_key(query_phones)
    if not qk_perfect: return []
    want = qk_slant if slant else qk_perfect

    out = []
    seen = set()
    for w, phones in cmu.items():
        if not phones: continue
        pk, sk = _last_syllable_key(phones)
        if not pk: continue
        key = sk if slant else pk
        if key != want: continue
        z = meta_zipf.get(w)
        if not _zipf_ok(z, zipf_max): continue
        if w in seen: continue
        seen.add(w)
        out.append({
            "word": w,
            "syllables": len(_split_syllables(phones)),
            "stress": "".join(str(_stress_digit(p)) for p in phones if _strip_stress(p) in _VOWELS and _stress_digit(p) >= 0) or "unknown",
            "meter": "mixed",  # simple placeholder
            "zipf": z,
        })
    out.sort(key=lambda r: (_rarity(r["zipf"]), r["word"]))
    return out[:max_items]

def build_buckets_cmu_only(term, cmu, meta_zipf, max_items, relax_rap, include_rap, zipf_max, min_each, zipf_max_multi):
    # parse query
    qp = _cmu_pron(term, cmu)
    if not qp: return {"uncommon": [], "slant": [], "multiword": [], "rap_targets": []}
    strict = _collect_cmu_candidates(qp, cmu, meta_zipf, zipf_max, max_items, slant=False)
    slant  = _collect_cmu_candidates(qp, cmu, meta_zipf, zipf_max, max_items, slant=True)
# --- recovery path: widen filters if all buckets empty before final return ---
_un = uncommon if "uncommon" in locals() else []
_sl = slant if "slant" in locals() else []
_mw = multiword if "multiword" in locals() else []
_rt = rap_targets if "rap_targets" in locals() else []

if not (_un or _sl or _mw or _rt):
    try:
        res2 = search_all_categories(term,
                                     max_items=max_items,
                                     relax_rap=True,
                                     include_rap=False,
                                     zipf_max=5.5,
                                     min_each=max(6, min_each // 2),
                                     zipf_max_multi=7.0)
        if isinstance(res2, dict) and any(res2.get(k) for k in ["uncommon","slant","multiword","rap_targets"]):
            return res2
    except Exception:
        pass

    try:
        rhy = [w["word"] for w in dm.related(term, "rhy", max_items=max_items)] if hasattr(dm, "related") else []
        nry = [w["word"] for w in getattr(dm, "near_rhymes", lambda t, max_items=20: [])(term, max_items=max_items)]
        if rhy or nry:
            return {"uncommon": rhy[:max_items],
                    "slant": nry[:max_items],
                    "multiword": [],
                    "rap_targets": []}
    except Exception:
        pass
    return {"uncommon": strict, "slant": slant, "multiword": [], "rap_targets": []}
# === END CMU CORE RHYMER ===

from rhyme_core.providers import datamuse as dm

