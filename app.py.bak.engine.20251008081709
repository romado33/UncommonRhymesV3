from pathlib import Path
import time
import os
import csv, io
import gradio as gr

# --- begin gradio_client bool-schema hotfix ---
try:
    import gradio_client.utils as _gcu

    _old_get_type = _gcu.get_type
    def _get_type_safe(schema):
        # JSON Schema can legally be True/False (accepts/denies everything).
        # Guard so utils doesn't do membership checks on a bool.
        if isinstance(schema, bool):
            return "object"
        return _old_get_type(schema)
    _gcu.get_type = _get_type_safe

    _old_to_py = _gcu._json_schema_to_python_type
    def _json_schema_to_python_type_safe(schema, defs=None):
        if isinstance(schema, bool):
            return "object"
        return _old_to_py(schema, defs)
    _gcu._json_schema_to_python_type = _json_schema_to_python_type_safe
except Exception:
    # If internals change in a future version, continue without the patch.
    pass
# --- end gradio_client bool-schema hotfix ---

from rhyme_core.search import search_all_categories
from rhyme_core.providers import datamuse as dm

# ---------- formatting helpers ----------
def _fmt_item(r: dict) -> str:
    """Format as 'word â€” Nsyl | 0101 | meter' (meter may be empty for rap rows)."""
    name = r.get("word") or r.get("target_word") or "?"
    syls = r.get("syls")
    stress = r.get("stress")
    meter = r.get("meter")
    parts = []
    if syls is not None and syls != "":
        parts.append(f"{syls} syl")
    if stress:
        parts.append(str(stress))
    if meter:
        parts.append(str(meter))
    suffix = " | ".join(parts) if parts else ""
    return f"{name} â€” {suffix}" if suffix else name

def _rows_to_csv(rows):
    f = io.StringIO()
    w = csv.writer(f)
    w.writerow(["rhyme", "why"])
    for rhyme, why in rows:
        w.writerow([rhyme, why])
    return f.getvalue()

def _pack_rows(items):
    return [[_fmt_item(r), r.get("why","")] for r in items]

def _fmt_query_line(res_dict):
    qi = res_dict.get("query_info")
    if not qi:
        return ""
    name = qi.get("word","?")
    syls = qi.get("syls","")
    stress = qi.get("stress","")
    meter = qi.get("meter","")
    parts = []
    if syls != "":
        parts.append(f"{syls} syl")
    if stress:
        parts.append(stress)
    if meter:
        parts.append(meter)
    meta = " | ".join(parts)
    return f"**Query:** {name}" + (f" â€” {meta}" if meta else "")

# ---------- Datamuse helpers (non-blocking, optional) ----------
def dm_suggest(prefix: str):
    p = (prefix or "").strip()
    if not p:
        return "(type above to get suggestions)"
    try:
        items = dm.sug(p, max_items=10)
        words = [it.get("word","") for it in items]
        return "Suggestions: " + (", ".join(words) if words else "(none)")
    except Exception:
        return "(suggestions unavailable)"

def dm_related(term: str):
    t = (term or "").strip()
    if not t:
        return "(enter a term above)"
    try:
        ml  = [w["word"] for w in dm.means_like(t, max_items=12)]
        syn = [w["word"] for w in dm.related(t,"syn", max_items=12)]
        trg = [w["word"] for w in dm.related(t,"trg", max_items=12)]
        adj = [w["word"] for w in dm.adjectives_for(t, max_items=12)]
        def line(lbl, arr): return f"**{lbl}:** " + (", ".join(arr) if arr else "â€”")
        return "\n\n".join([
            line("Means-like", ml),
            line("Synonyms", syn),
            line("Triggers", trg),
            line(f'Adjectives for â€œ{t}â€', adj),
        ])
    except Exception:
        return "(related words unavailable)"

# ---------- main analyze callbacks ----------
def go(term, max_items, relax_rap, include_rap, zipf_cutoff, min_each, zipf_cutoff_multi):
    term = (term or "").strip()
    if not term:
        empty_tbl = [["Enter a term above.", ""]]
        empty_csv = _rows_to_csv([("Enter a term above.", "")])
        return "", empty_tbl, empty_tbl, empty_tbl, empty_tbl, empty_csv, empty_csv, empty_csv, empty_csv, ""

    res = search_all_categories(
        term,
        max_items=int(max_items),
        relax_rap=bool(relax_rap),
        include_rap=bool(include_rap),
        zipf_max=float(zipf_cutoff),
        min_each=int(min_each),
        zipf_max_multi=float(zipf_cutoff_multi),
    )

    query_line = _fmt_query_line(res)

    # Tables
    uncommon_tbl = _pack_rows(res.get("uncommon", []))
    slant_tbl    = _pack_rows(res.get("slant", []))
    multi_tbl    = _pack_rows(res.get("multiword", []))
    rap_tbl      = _pack_rows(res.get("rap_targets", []))

    # CSVs
    def no_ellipsis(rows): return [r for r in rows if not str(r[0]).startswith("...")]
    unc_csv = _rows_to_csv(no_ellipsis(uncommon_tbl))
    slt_csv = _rows_to_csv(no_ellipsis(slant_tbl))
    mul_csv = _rows_to_csv(no_ellipsis(multi_tbl))
    rap_csv = _rows_to_csv(no_ellipsis(rap_tbl))

    keys = res.get("keys", {})
    focus = res.get("focus_word", "")
    debug = (f"focus='{focus}' | k1={keys.get('k1','')} k2={keys.get('k2','')} k3={keys.get('k3','')} "
             f"| zipfâ‰¤{zipf_cutoff} (perfect/slant), multiword zipfâ‰¤{zipf_cutoff_multi}, min_each={min_each}")

    return query_line, uncommon_tbl, slant_tbl, multi_tbl, rap_tbl, unc_csv, slt_csv, mul_csv, rap_csv, debug

def show_all(term, bucket, relax_rap, include_rap, zipf_cutoff, min_each, zipf_cutoff_multi):
    res = search_all_categories(
        (term or "").strip(),
        max_items=10_000,
        relax_rap=bool(relax_rap),
        include_rap=bool(include_rap),
        zipf_max=float(zipf_cutoff),
        min_each=int(min_each),
        zipf_max_multi=float(zipf_cutoff_multi),
    )
    return _pack_rows(res.get(bucket, []))

# ---------- UI ----------
with gr.Blocks() as demo:
    gr.Markdown("# UncommonRhymesV3 â€” functional build")

    with gr.Row():
        term = gr.Textbox(label="Word or phrase", scale=3, value="double")
        max_items = gr.Slider(5, 100, value=20, step=1, label="Max per category")
        zipf_cutoff = gr.Slider(2.5, 7.0, value=4.0, step=0.1, label="Zipf cutoff (perfect/slant â‰¤)")
        zipf_cutoff_multi = gr.Slider(3.0, 7.5, value=5.5, step=0.1, label="Zipf cutoff (multiword â‰¤)")
        min_each = gr.Slider(1, 30, value=10, step=1, label="Min per bucket (top-up target)")

    with gr.Row():
        relax_rap = gr.Checkbox(value=True, label="Relax rap matching (use assonance if few)")
        include_rap = gr.Checkbox(value=False, label="Include rap targets")

    with gr.Row():
        sugg_btn = gr.Button("Suggest spellings/sounds (Datamuse)")
        rel_btn  = gr.Button("Related words (Datamuse)")
    sugg_md = gr.Markdown()
    rel_md  = gr.Markdown()

    btn = gr.Button("Analyze", variant="primary")

    query_md = gr.Markdown()

    with gr.Tabs():
        with gr.Tab("Benchmarks"):
            gr.Markdown("Run benchmarks on a list of query terms (reads `benchmark.queries_used.txt` if present).")
            with gr.Row():
                bm_max = gr.Slider(5, 100, value=20, step=1, label="Max per category")
                bm_zipf = gr.Slider(2.5, 7.0, value=4.0, step=0.1, label="Zipf cutoff perfect/slant â‰¤")
                bm_zipf_multi = gr.Slider(3.0, 7.5, value=5.5, step=0.1, label="Zipf cutoff multiword â‰¤")
                bm_min_each = gr.Slider(1, 40, value=10, step=1, label="Min per bucket")
            with gr.Row():
                bm_relax_rap = gr.Checkbox(value=True, label="Relax rap matching")
                bm_include_rap = gr.Checkbox(value=False, label="Include rap targets")
            bm_btn = gr.Button("Run Benchmarks", variant="primary")
            bm_table = gr.Dataframe(headers=["term","uncommon","slant","multiword","rap_targets","elapsed_ms"], interactive=False)
            bm_summary = gr.Textbox(label="Summary", lines=14, interactive=False)
            bm_file = gr.File(label="Download CSV", interactive=False)

            def _do_bench(bm_max, bm_relax_rap, bm_include_rap, bm_zipf, bm_min_each, bm_zipf_multi):
                terms = _bench_load_terms()
                rows, summary, out_csv = _bench_run(
                    terms, int(bm_max), bool(bm_relax_rap), bool(bm_include_rap),
                    float(bm_zipf), int(bm_min_each), float(bm_zipf_multi)
                )
                # Dataframe wants list of lists
                table = [[r["term"], r["uncommon"], r["slant"], r["multiword"], r["rap_targets"], r["elapsed_ms"]] for r in rows]
                return table, summary, out_csv

            bm_btn.click(
                _do_bench,
                inputs=[bm_max, bm_relax_rap, bm_include_rap, bm_zipf, bm_min_each, bm_zipf_multi],
                outputs=[bm_table, bm_summary, bm_file]
            )
        with gr.Tab("Uncommon Rhymes (perfect & uncommon)"):
            uncommon = gr.Dataframe(headers=["Rhyme", "Why"], interactive=False)
            show_all_unc = gr.Button("Show full list")
            with gr.Accordion("CSV (copy/paste)", open=False):
                unc_csv_txt = gr.Textbox(lines=8, show_label=False)

        with gr.Tab("Slant Rhymes (imperfect & uncommon)"):
            slant = gr.Dataframe(headers=["Rhyme", "Why"], interactive=False)
            show_all_slt = gr.Button("Show full list")
            with gr.Accordion("CSV (copy/paste)", open=False):
                slt_csv_txt = gr.Textbox(lines=8, show_label=False)

        with gr.Tab("Multiword Rhymes (CMU combinations)"):
            multi = gr.Dataframe(headers=["Rhyme", "Why"], interactive=False)
            show_all_mul = gr.Button("Show full list")
            with gr.Accordion("CSV (copy/paste)", open=False):
                mul_csv_txt = gr.Textbox(lines=8, show_label=False)

        with gr.Tab("Rap Targets"):
            rap = gr.Dataframe(headers=["Rhyme", "Why"], interactive=False)
            show_all_rap = gr.Button("Show full list")
            with gr.Accordion("CSV (copy/paste)", open=False):
                rap_csv_txt = gr.Textbox(lines=8, show_label=False)

    debug = gr.Markdown()

    # main analyze
    btn.click(
        go,
        inputs=[term, max_items, relax_rap, include_rap, zipf_cutoff, min_each, zipf_cutoff_multi],
        outputs=[query_md, uncommon, slant, multi, rap, unc_csv_txt, slt_csv_txt, mul_csv_txt, rap_csv_txt, debug],
    )

    # show full handlers
    show_all_unc.click(
        show_all,
        inputs=[term, gr.State("uncommon"), relax_rap, include_rap, zipf_cutoff, min_each, zipf_cutoff_multi],
        outputs=uncommon,
    )
    show_all_slt.click(
        show_all,
        inputs=[term, gr.State("slant"), relax_rap, include_rap, zipf_cutoff, min_each, zipf_cutoff_multi],
        outputs=slant,
    )
    show_all_mul.click(
        show_all,
        inputs=[term, gr.State("multiword"), relax_rap, include_rap, zipf_cutoff, min_each, zipf_cutoff_multi],
        outputs=multi,
    )
    show_all_rap.click(
        show_all,
        inputs=[term, gr.State("rap_targets"), relax_rap, include_rap, zipf_cutoff, min_each, zipf_cutoff_multi],
        outputs=rap,
    )

    # Datamuse hooks
    sugg_btn.click(dm_suggest, inputs=[term], outputs=[sugg_md])
    rel_btn.click(dm_related, inputs=[term], outputs=[rel_md])

if __name__ == "__main__":
    demo.launch(share=False, server_name="127.0.0.1", server_port=7860, inbrowser=False, show_api=False)



from rhyme_core.providers import datamuse as dm

def dm_suggest(prefix):
    if not prefix.strip(): return "(type to get suggestions)"
    try:
        items = dm.sug(prefix, max_items=10)
        return "Suggestions: " + ", ".join([i.get("word","") for i in items]) or "(none)"
    except Exception:
        return "(suggestions unavailable)"

def dm_related(term):
    term = (term or "").strip()
    if not term: return "(enter a term above)"
    try:
        ml  = [w["word"] for w in dm.means_like(term, max_items=12)]
        syn = [w["word"] for w in dm.related(term,"syn", max_items=12)]
        trg = [w["word"] for w in dm.related(term,"trg", max_items=12)]
        adj = [w["word"] for w in dm.adjectives_for(term, max_items=12)]
        return f"**Means-like:** {', '.join(ml)}\n\n**Synonyms:** {', '.join(syn)}\n\n**Triggers:** {', '.join(trg)}\n\n**Adjectives for â€œ{term}â€:** {', '.join(adj)}"
    except Exception:
        return "(related words unavailable)"




# ---------- Benchmark helpers ----------
def _bench_load_terms() -> list[str]:
    candidates = [
        Path("benchmark.queries_used.txt"),
        Path("data/dev/benchmark.queries_used.txt"),
        Path("tests/benchmark.queries_used.txt"),
    ]
    for p in candidates:
        if p.exists():
            terms = []
            for ln in p.read_text(encoding="utf-8").splitlines():
                t = (ln or "").strip()
                if t and not t.startswith("#"):
                    terms.append(t)
            return terms
    # fallback small set
    return ["double", "orange", "guitar", "time", "love"]

def _bench_run(terms: list[str], max_items: int, relax_rap: bool, include_rap: bool,
               zipf_cutoff: float, min_each: int, zipf_cutoff_multi: float):
    rows = []
    start_all = time.perf_counter()
    for t in terms:
        t0 = time.perf_counter()
        res = search_all_categories(
            t, max_items=max_items, relax_rap=relax_rap, include_rap=include_rap,
            zipf_max=zipf_cutoff, min_each=min_each, zipf_max_multi=zipf_cutoff_multi
        )
        dur_ms = round((time.perf_counter() - t0) * 1000.0, 2)
        rows.append({
            "term": t,
            "uncommon": len(res.get("uncommon", [])),
            "slant": len(res.get("slant", [])),
            "multiword": len(res.get("multiword", [])),
            "rap_targets": len(res.get("rap_targets", [])),
            "elapsed_ms": dur_ms
        })
    total_ms = round((time.perf_counter() - start_all) * 1000.0, 2)
    summary = {
        "terms": len(terms),
        "total_ms": total_ms,
        "avg_ms": round(total_ms / max(1, len(terms)), 2),
        "avg_uncommon": round(sum(r["uncommon"] for r in rows) / max(1, len(rows)), 2),
        "avg_slant": round(sum(r["slant"] for r in rows) / max(1, len(rows)), 2),
        "avg_multiword": round(sum(r["multiword"] for r in rows) / max(1, len(rows)), 2),
        "avg_rap": round(sum(r["rap_targets"] for r in rows) / max(1, len(rows)), 2),
    }
    # Write CSV
    out_dir = Path("data/dev/benchmarks"); out_dir.mkdir(parents=True, exist_ok=True)
    out_csv = out_dir / "latest_benchmark.csv"
    with out_csv.open("w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        w.writerow(["term","uncommon","slant","multiword","rap_targets","elapsed_ms"])
        for r in rows:
            w.writerow([r["term"], r["uncommon"], r["slant"], r["multiword"], r["rap_targets"], r["elapsed_ms"]])
    return rows, summary, str(out_csv)



import json
if __name__ == "__main__":
    demo.launch(share=False, server_port=7860, inbrowser=False)






